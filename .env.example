# ===========================================
# Hackerecon - Примеры конфигураций LLM
# ===========================================

# ============================================
# ВАРИАНТ 1: Gemini (по умолчанию)
# ============================================
LLM_PROVIDER=gemini
LLM_MODEL=gemini-1.5-pro
API_KEY=your-google-api-key-here

# ============================================
# ВАРИАНТ 2: Ollama (локально)
# ============================================
# LLM_PROVIDER=generic
# LLM_FORMAT=ollama
# LLM_BASE_URL=http://localhost:11434
# LLM_MODEL=llama3.1:8b
# API_KEY=  # Не требуется для Ollama

# ============================================
# ВАРИАНТ 3: LM Studio (локально)
# ============================================
# LLM_PROVIDER=generic
# LLM_FORMAT=openai
# LLM_BASE_URL=http://localhost:1234
# API_KEY=  # Не требуется

# ============================================
# ВАРИАНТ 4: LocalAI (локально)
# ============================================
# LLM_PROVIDER=generic
# LLM_FORMAT=openai
# LLM_BASE_URL=http://localhost:8080
# API_KEY=  # Опционально

# ============================================
# ВАРИАНТ 5: vLLM сервер
# ============================================
# LLM_PROVIDER=generic
# LLM_FORMAT=openai
# LLM_BASE_URL=https://your-vllm-server.com
# API_KEY=your-api-key

# ============================================
# ВАРИАНТ 6: Произвольный OpenAI-compatible API
# ============================================
# LLM_PROVIDER=generic
# LLM_FORMAT=openai
# LLM_BASE_URL=https://api.example.com
# API_KEY=your-api-key

# ============================================
# Другие настройки
# ============================================
PORT=8080
PROXY_LISTEN_ADDR=:8081
WEB_LISTEN_ADDR=:8080
PROXY_CERT_FILE=./certs/ca.pem

# Burp Suite интеграция (опционально)
BURP_HOST=127.0.0.1
BURP_PORT=8080
