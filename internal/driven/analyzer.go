package driven

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/BetterCallFirewall/Hackerecon/internal/llm"
	"github.com/BetterCallFirewall/Hackerecon/internal/models"
	"github.com/BetterCallFirewall/Hackerecon/internal/utils"
	"github.com/BetterCallFirewall/Hackerecon/internal/verification"
	"github.com/BetterCallFirewall/Hackerecon/internal/websocket"
	"github.com/PuerkitoBio/goquery"
	genkitcore "github.com/firebase/genkit/go/core"
	"github.com/firebase/genkit/go/genkit"
	"github.com/google/uuid"
)

// GenkitSecurityAnalyzer –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTTP —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
// –∏—Å–ø–æ–ª—å–∑—É—è LLM –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
// –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≥–∏–ø–æ—Ç–µ–∑ –æ–± —É—è–∑–≤–∏–º–æ—Å—Ç—è—Ö.
type GenkitSecurityAnalyzer struct {
	// Core components
	llmProvider llm.Provider
	WsHub       *websocket.WebsocketManager
	genkitApp   *genkit.Genkit

	// Analysis flow (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç SecurityAnalysisResponse –∏–ª–∏ nil –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ –Ω—É–∂–µ–Ω)
	unifiedAnalysisFlow *genkitcore.Flow[*models.SecurityAnalysisRequest, *models.SecurityAnalysisResponse, struct{}]

	// Verification flow
	verificationFlow *genkitcore.Flow[*models.VerificationRequest, *models.VerificationResponse, struct{}]

	// Modular components
	contextManager *SiteContextManager
	dataExtractor  *DataExtractor
	hypothesisGen  *HypothesisGenerator
	requestFilter  *utils.RequestFilter

	// Verification client
	verificationClient *verification.VerificationClient

	// URL Analysis cache (90% LLM reduction)
	urlCache *URLAnalysisCache

	// Enhanced SiteContext tracking
	formExtractor   *utils.FormExtractor
	crudMapper      *utils.CRUDMapper
	temporalTracker *utils.TemporalTracker
}

// NewGenkitSecurityAnalyzer —Å–æ–∑–¥–∞—ë—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º
func NewGenkitSecurityAnalyzer(
	genkitApp *genkit.Genkit,
	provider llm.Provider,
	wsHub *websocket.WebsocketManager,
) (*GenkitSecurityAnalyzer, error) {
	analyzer := &GenkitSecurityAnalyzer{
		llmProvider: provider,
		WsHub:       wsHub,
		genkitApp:   genkitApp,

		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
		contextManager:  NewSiteContextManager(),
		requestFilter:   utils.NewRequestFilter(),
		urlCache:        NewURLAnalysisCache(1000), // –ö—ç—à –Ω–∞ 1000 URL –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
		formExtractor:   utils.NewFormExtractor(),
		crudMapper:      utils.NewCRUDMapper(),
		temporalTracker: utils.NewTemporalTracker(),
	}

	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è data extractor
	analyzer.dataExtractor = NewDataExtractor()

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º unified flow —Å orchestration –¥–≤—É—Ö LLM –≤—ã–∑–æ–≤–æ–≤
	analyzer.unifiedAnalysisFlow = genkit.DefineFlow(
		genkitApp, "unifiedAnalysisFlow",
		func(ctx context.Context, req *models.SecurityAnalysisRequest) (*models.SecurityAnalysisResponse, error) {
			// Step 1: Quick URL Analysis (traced)
			// –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
			urlPattern := normalizeURLPattern(req.URL)
			cacheKey := fmt.Sprintf("%s:%s", req.Method, urlPattern)

			var urlAnalysisResp *models.URLAnalysisResponse
			if cached, ok := analyzer.urlCache.Get(cacheKey); ok {
				// Cache hit! –ü—Ä–æ–ø—É—Å–∫–∞–µ–º LLM –≤—ã–∑–æ–≤
				log.Printf("‚úÖ Cache HIT: %s %s", req.Method, urlPattern)
				urlAnalysisResp = cached
			} else {
				// Cache miss - –¥–µ–ª–∞–µ–º LLM –∑–∞–ø—Ä–æ—Å
				log.Printf("‚ùå Cache MISS: %s %s", req.Method, urlPattern)

				// –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ 500 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
				urlAnalysisReq := &models.URLAnalysisRequest{
					URL:          req.URL,
					Method:       req.Method,
					Headers:      req.Headers,
					ResponseBody: llm.TruncateString(req.ResponseBody, 500), // –¢–æ–ª—å–∫–æ 500 —Å–∏–º–≤–æ–ª–æ–≤!
					ContentType:  req.ContentType,
					SiteContext:  req.SiteContext,
				}

				var err error
				urlAnalysisResp, err = genkit.Run(
					ctx, "quick-url-analysis", func() (*models.URLAnalysisResponse, error) {
						return analyzer.llmProvider.GenerateURLAnalysis(ctx, urlAnalysisReq)
					},
				)
				if err != nil {
					return nil, fmt.Errorf("quick URL analysis failed: %w", err)
				}

				// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
				analyzer.urlCache.Set(cacheKey, urlAnalysisResp)
			}

			// Step 2: Update URL pattern –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–≤—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º –∑–∞–º–µ—Ç–∫–∏)
			if req.SiteContext != nil {
				analyzer.updateURLPattern(req.SiteContext, req.URL, req.Method, urlAnalysisResp)
			}

			// Step 3: –†–µ—à–∞–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Ç–æ–ª—å–∫–æ –¥–ª—è high interest)
			// –î–ª—è medium –∏ low - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
			if urlAnalysisResp.InterestLevel != "high" {
				// –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω –¥–ª—è low/medium - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
				// WebSocket –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω —Ç–æ–ª—å–∫–æ —Å observations –∏–∑ Quick Analysis
				return &models.SecurityAnalysisResponse{
					Summary:         "Endpoint —Å " + urlAnalysisResp.InterestLevel + " –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º",
					Findings:        []models.Finding{}, // –ù–µ—Ç findings –¥–ª—è low/medium
					ContextForLater: models.ContextForLater{},
				}, nil
			}

			// Step 4: –¢–µ–ø–µ—Ä—å –≥–æ—Ç–æ–≤–∏–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è Full Analysis (—Ç–æ–ª—å–∫–æ –¥–ª—è high)
			req.RequestBody = analyzer.prepareContentForLLM(req.RequestBody, req.Headers["Content-Type"])
			req.ResponseBody = analyzer.prepareContentForLLM(req.ResponseBody, req.ContentType)

			// Step 5: Extract data —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
			if analyzer.shouldExtractData(req.ContentType, req.ResponseBody) {
				extractedData, err := genkit.Run(
					ctx, "extract-data", func() (models.ExtractedData, error) {
						return analyzer.dataExtractor.ExtractFromContent(
							req.RequestBody,
							req.ResponseBody,
							req.ContentType,
						), nil
					},
				)
				if err != nil {
					return nil, err
				}
				req.ExtractedData = extractedData
			} else {
				// –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ overhead genkit.Run
				req.ExtractedData = models.ExtractedData{
					FormActions: []string{},
					Comments:    []string{},
				}
			}

			// Step 6: Full Security Analysis (traced)
			securityResp, err := genkit.Run(
				ctx, "full-security-analysis", func() (*models.SecurityAnalysisResponse, error) {
					return analyzer.llmProvider.GenerateSecurityAnalysis(ctx, req)
				},
			)
			if err != nil {
				return nil, fmt.Errorf("security analysis failed: %w", err)
			}

			// Step 7: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º findings –¥–æ 5 –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
			if securityResp != nil && len(securityResp.Findings) > 5 {
				// –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ impact/effort
				sort.Slice(
					securityResp.Findings, func(i, j int) bool {
						return priorityScore(securityResp.Findings[i]) > priorityScore(securityResp.Findings[j])
					},
				)
				securityResp.Findings = securityResp.Findings[:5]
			}

			return securityResp, nil
		},
	)

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º flow –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–∏–ø–æ—Ç–µ–∑ —Å orchestration
	hypothesisFlow := genkit.DefineFlow(
		genkitApp, "hypothesisFlow",
		func(ctx context.Context, req *models.HypothesisRequest) (*models.HypothesisResponse, error) {
			// LLM hypothesis generation —Å —Ç—Ä–µ–π—Å–∏–Ω–≥–æ–º
			result, err := genkit.Run(
				ctx, "llm-hypothesis-generation", func() (*models.HypothesisResponse, error) {
					return analyzer.llmProvider.GenerateHypothesis(ctx, req)
				},
			)
			if err != nil {
				return nil, fmt.Errorf("failed to generate hypothesis: %w", err)
			}

			return result, nil
		},
	)

	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –≥–∏–ø–æ—Ç–µ–∑
	analyzer.hypothesisGen = NewHypothesisGenerator(
		hypothesisFlow,
		wsHub,
		analyzer.contextManager,
	)

	// Initialize verification client
	analyzer.verificationClient = verification.NewVerificationClient(
		verification.VerificationClientConfig{
			Timeout:    30 * time.Second,
			MaxRetries: 2,
		},
	)

	// Initialize verification flow
	analyzer.verificationFlow = genkit.DefineFlow(
		analyzer.genkitApp,
		"verificationFlow",
		func(ctx context.Context, req *models.VerificationRequest) (*models.VerificationResponse, error) {
			// Generate hypothesis from checklist item
			hypothesis := req.ChecklistItem.Action + " - " + req.ChecklistItem.Description
			return analyzer.verifyHypothesis(ctx, req, hypothesis)
		},
	)

	return analyzer, nil
}

// AnalyzeHTTPTraffic –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTTP —Ç—Ä–∞—Ñ–∏–∫ —Å unified flow
func (analyzer *GenkitSecurityAnalyzer) AnalyzeHTTPTraffic(
	ctx context.Context, req *http.Request, resp *http.Response, reqBody, respBody, contentType string,
) error {
	// 1. –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
	shouldSkip, reason := analyzer.requestFilter.ShouldSkipRequestWithReason(req, resp, contentType)
	if shouldSkip {
		log.Printf("‚ö™Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ %s %s: %s", req.Method, req.URL.String(), reason)
		return nil // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
	}

	log.Printf("üîç –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: %s %s (Content-Type: %s)", req.Method, req.URL.String(), contentType)

	// 2. –ü–æ–ª—É—á–∞–µ–º/—Å–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–∞–π—Ç–∞ (LLM –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π)
	siteContext := analyzer.getOrCreateSiteContext(req.URL.Host)

	// 3. Enhanced SiteContext tracking - collect data for LLM context
	startTime := time.Now()

	// Track temporal request history
	if err := analyzer.temporalTracker.TrackRequest(
		siteContext,
		req.Method,
		req.URL.Path,
		resp.StatusCode,
		int64(time.Since(startTime).Nanoseconds()/1e6), // duration in ms
		req.Referer(),
	); err != nil {
		log.Printf("‚ö†Ô∏è Failed to track temporal request: %v", err)
	}

	// Extract forms from HTML responses
	if strings.Contains(contentType, "html") && respBody != "" {
		forms := analyzer.formExtractor.ExtractForms(respBody)
		for _, form := range forms {
			// Add form to site context (avoid duplicates)
			if _, exists := siteContext.Forms[form.FormID]; !exists {
				form.FirstSeen = time.Now().Unix()
				siteContext.Forms[form.FormID] = form
				log.Printf(
					"üìã Extracted form: %s %s (Fields: %d, CSRF: %v)",
					form.Method, form.Action, len(form.Fields), form.HasCSRFToken,
				)
			}
		}
	}

	// Map CRUD operations for API requests
	analyzer.crudMapper.UpdateResourceMapping(siteContext, req.Method, req.URL.String())

	// 4. Unified –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –æ–¥–∏–Ω orchestration flow
	//    Quick Analysis –≤—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è - LLM —Å–∞–º —Ä–µ—à–∞–µ—Ç –Ω—É–∂–µ–Ω –ª–∏ Full Analysis
	//    –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–∞–π—Ç–∞ –∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

	// –õ–µ–Ω–∏–≤–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞: –º–∏–Ω–∏–º—É–º –¥–ª—è Quick Analysis
	analysisReq := &models.SecurityAnalysisRequest{
		URL:    req.URL.String(),
		Method: req.Method,
		Headers: func() map[string]string {
			headers := make(map[string]string)
			for k, v := range req.Header {
				if len(v) > 0 {
					headers[k] = v[0]
				}
			}
			return headers
		}(),
		RequestBody:  reqBody,  // –•—Ä–∞–Ω–∏–º raw –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
		ResponseBody: respBody, // –•—Ä–∞–Ω–∏–º raw –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
		ContentType:  contentType,
		ExtractedData: models.ExtractedData{
			FormActions: []string{},
			Comments:    []string{},
		},
		SiteContext: siteContext,
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º unified flow (Quick ‚Üí Full –µ—Å–ª–∏ LLM —Ä–µ—à–∏—Ç)
	securityAnalysis, err := analyzer.unifiedAnalysisFlow.Run(ctx, analysisReq)
	if err != nil {
		log.Printf("‚ùå Unified analysis failed: %v", err)
		return err
	}

	// 5. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ WebSocket
	analyzer.broadcastAnalysisResult(req, resp, securityAnalysis, reqBody, respBody, siteContext)

	// 6. –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
	if securityAnalysis != nil && len(securityAnalysis.Findings) > 0 {
		log.Printf(
			"üî¨ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è %s %s (–Ω–∞–π–¥–µ–Ω–æ findings: %d)",
			req.Method, req.URL.String(), len(securityAnalysis.Findings),
		)
	} else {
		log.Printf("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è %s %s", req.Method, req.URL.String())
	}

	return nil
}

// broadcastAnalysisResult –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ WebSocket
func (analyzer *GenkitSecurityAnalyzer) broadcastAnalysisResult(
	req *http.Request,
	resp *http.Response,
	result *models.SecurityAnalysisResponse,
	reqBody, respBody string,
	siteContext *models.SiteContext,
) {
	// –õ–æ–≥–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏
	for _, finding := range result.Findings {
		if finding.Impact == "high" || finding.Impact == "critical" {
			log.Printf("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –£–Ø–ó–í–ò–ú–û–°–¢–¨: %s - %s", req.URL.String(), finding.Title)
			log.Printf("üí° –ù–∞–±–ª—é–¥–µ–Ω–∏–µ: %s", finding.Observation)
		}
	}

	// Convert request info
	requestInfo := models.RequestResponseInfo{
		URL:        req.URL.String(),
		Method:     req.Method,
		StatusCode: resp.StatusCode,
		ReqHeaders: func() map[string]string {
			headers := make(map[string]string)
			for k, v := range req.Header {
				if len(v) > 0 {
					headers[k] = v[0]
				}
			}
			return headers
		}(),
		RespHeaders: func() map[string]string {
			headers := make(map[string]string)
			for k, v := range resp.Header {
				if len(v) > 0 {
					headers[k] = v[0]
				}
			}
			return headers
		}(),
		ReqBody:  llm.TruncateString(reqBody, maxContentSizeForLLM),
		RespBody: llm.TruncateString(respBody, maxContentSizeForLLM),
	}

	// Run parallel verification for findings
	if len(result.Findings) > 0 {
		// PHASE 0: Smart pre-filtering - skip obvious cases
		originalCount := len(result.Findings)
		result.Findings = analyzer.filterFindingsForVerification(result.Findings, siteContext)

		if originalCount != len(result.Findings) {
			log.Printf(
				"üîç Pre-filtering: %d findings ‚Üí %d (filtered %d)",
				originalCount, len(result.Findings), originalCount-len(result.Findings),
			)
		}

		// PHASE 1-2: Heuristic + LLM verification
		if len(result.Findings) > 0 {
			log.Printf("üî¨ Starting batch verification for %d findings", len(result.Findings))
			analyzer.verifyFindingsBatch(result.Findings, requestInfo, siteContext)

			// Filter out findings that were disproven by verification
			originalCount := len(result.Findings)
			validFindings := make([]models.Finding, 0, len(result.Findings))

			for _, finding := range result.Findings {
				if finding.VerificationStatus == "likely_false" {
					log.Printf("üóëÔ∏è  Filtering out disproven finding: %s", finding.Title)
					continue
				}
				validFindings = append(validFindings, finding)
			}

			result.Findings = validFindings

			if originalCount != len(validFindings) {
				log.Printf(
					"‚úÖ Verification completed: %d findings kept, %d filtered out",
					len(validFindings), originalCount-len(validFindings),
				)
			} else {
				log.Printf("‚úÖ Verification completed: all %d findings kept", len(validFindings))
			}
		}
	}

	// Broadcast final result with verified findings
	reportID := uuid.New().String()
	analyzer.WsHub.Broadcast(
		models.ReportDTO{
			Report: models.VulnerabilityReport{
				ID:             reportID,
				Timestamp:      time.Now(),
				AnalysisResult: *result,
			},
			RequestResponse: requestInfo,
		},
	)
}

// verifyFindingsBatch –≤—ã–ø–æ–ª–Ω—è–µ—Ç –±–∞—Ç—á-–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é –≤—Å–µ—Ö findings –∑–∞ –æ–¥–∏–Ω LLM –≤—ã–∑–æ–≤
// –≠—Ç–æ –Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ —á–µ–º verifyFindingsParallel (1 call –≤–º–µ—Å—Ç–æ N)
func (analyzer *GenkitSecurityAnalyzer) verifyFindingsBatch(
	findings []models.Finding,
	requestInfo models.RequestResponseInfo,
	siteContext *models.SiteContext,
) {
	if len(findings) == 0 {
		return
	}

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)
	defer cancel()

	log.Printf("üöÄ Starting batch verification for %d findings", len(findings))

	// PHASE 1: Execute all test requests in parallel
	testResults := make([]models.TestRequestForBatch, 0, len(findings))
	var wg sync.WaitGroup
	var mu sync.Mutex

	maxConcurrent := 3
	sem := make(chan struct{}, maxConcurrent)

	for i := range findings {
		// IMPORTANT FIX: Set original index for O(1) lookup in heuristic phase
		findings[i].OriginalIndex = i

		wg.Add(1)
		go func(idx int, finding *models.Finding) {
			defer wg.Done()

			// CRITICAL FIX: Check immediately after entering goroutine, before any access
			if len(finding.TestRequests) == 0 {
				log.Printf("‚ö†Ô∏è Finding %s has no test requests, skipping", finding.Title)
				return
			}

			defer func() {
				if r := recover(); r != nil {
					log.Printf("‚ö†Ô∏è PANIC in verifyFindingsBatch goroutine: %v", r)
				}
			}()
			// Acquire semaphore
			sem <- struct{}{}
			defer func() { <-sem }()

			// Execute all test requests for this finding in parallel
			var testResultsForFinding []models.TestResultForBatch
			var wgTest sync.WaitGroup

			// IMPORTANT FIX: Limit concurrent tests per finding (max 3 concurrent tests)
			maxConcurrentTests := 3
			semTest := make(chan struct{}, maxConcurrentTests)

			for testIdx, testReq := range finding.TestRequests {
				wgTest.Add(1)
				go func(tIdx int, tReq models.TestRequest) {
					defer wgTest.Done()

					// Acquire test semaphore (max 3 concurrent tests)
					semTest <- struct{}{}
					defer func() { <-semTest }() // IMPORTANT: Release with defer

					// Execute test request
					testResult := analyzer.executeTestRequest(ctx, tReq, requestInfo)

					mu.Lock()
					testResultsForFinding = append(testResultsForFinding, models.TestResultForBatch{
						TestIndex:    tIdx,
						StatusCode:   testResult.StatusCode,
						ResponseBody: llm.TruncateString(testResult.ResponseBody, 2000),
						Error:        testResult.Error,
						Purpose:      tReq.Purpose, // From the test request
					})
					mu.Unlock()

					log.Printf("‚úÖ Executed test %d for finding %d: %s", tIdx, idx, finding.Title)
				}(testIdx, testReq)
			}

			wgTest.Wait()

			// Add to batch results (already validated that TestRequests is not empty)
			mu.Lock()

			testResults = append(testResults, models.TestRequestForBatch{
				FindingIndex: idx, // IMPORTANT FIX: Store index for O(1) lookup
				// IMPORTANT FIX: Use requestInfo.URL instead of always using test request URL
				FindingURL: func() string {
					if requestInfo.URL != "" {
						return requestInfo.URL
					}
					if len(finding.TestRequests) > 0 {
						return finding.TestRequests[0].URL
					}
					return "unknown"
				}(),
				FindingTitle: finding.Title,
				TestResults:  testResultsForFinding,
			})
			mu.Unlock()
		}(i, &findings[i])
	}

	wg.Wait()

	// PHASE 2: Heuristic analysis on test results
	heuristicDecisions := 0

	// IMPORTANT FIX: Create map for O(1) lookup by FindingIndex
	testResultsMap := make(map[int]models.TestRequestForBatch)
	for _, reqForBatch := range testResults {
		testResultsMap[reqForBatch.FindingIndex] = reqForBatch
	}

	for _, finding := range findings {
		var bestStatus string
		var bestConfidence float64
		var bestReason string

		// Try heuristic analysis on ALL test results for this finding
		originalResp := &models.ResponseData{
			StatusCode: requestInfo.StatusCode,
			Body:       requestInfo.RespBody,
		}

		// IMPORTANT FIX: Direct O(1) lookup instead of O(n¬≤) nested loop
		// Find the corresponding test results using the finding's original index
		if requestForFinding, ok := testResultsMap[finding.OriginalIndex]; ok {
			// Check if ANY test indicates vulnerability
			for _, testResult := range requestForFinding.TestResults {
				status, confidence, reason := utils.QuickHeuristicAnalysis(&finding, &models.TestResult{
					StatusCode:   testResult.StatusCode,
					ResponseBody: testResult.ResponseBody,
					Error:        testResult.Error,
				}, originalResp)

				// Track the most confident result
				if confidence > bestConfidence {
					bestStatus = status
					bestConfidence = confidence
					bestReason = reason
				}
			}
		}

		// If ANY test shows vulnerability (bestStatus != "needs_llm"), use that result
		if bestStatus != "" && bestStatus != "needs_llm" {
			finding.VerificationStatus = bestStatus
			finding.VerificationReason = fmt.Sprintf("Heuristic (%.0f%% confidence): %s", bestConfidence*100, bestReason)
			log.Printf("‚ö° Heuristic HIT (%.0f%%): %s - %s", bestConfidence*100, finding.Title, bestStatus)
			heuristicDecisions++
		}
	}

	// Filter findings that were decided by heuristics
	needsLLM := make([]models.Finding, 0, len(findings))
	needsLLMIndices := make([]int, 0, len(findings))

	for i, finding := range findings {
		if finding.VerificationStatus == "" {
			needsLLM = append(needsLLM, finding)
			needsLLMIndices = append(needsLLMIndices, i)
		}
	}

	log.Printf(
		"üìä Heuristic decisions: %d/%d, LLM needed: %d/%d",
		heuristicDecisions, len(findings), len(needsLLM), len(findings),
	)

	// PHASE 3: LLM batch analysis (only if needed)
	if len(needsLLM) > 0 {
		batchReq := &models.BatchVerificationRequest{
			Findings:        make([]models.FindingForBatchVerification, len(needsLLM)),
			OriginalRequest: requestInfo,
			TestResults:     testResults,
		}

		// Build finding list for LLM
		for i, finding := range needsLLM {
			batchReq.Findings[i] = models.FindingForBatchVerification{
				Index:                i,
				Title:                finding.Title,
				Observation:          finding.Observation,
				ExpectedIfVulnerable: finding.ExpectedIfVulnerable,
				ExpectedIfSafe:       finding.ExpectedIfSafe,
			}
		}

		// Call LLM for batch analysis
		batchResult, err := analyzer.llmProvider.AnalyzeBatchVerification(ctx, batchReq)
		if err != nil {
			log.Printf("‚ùå Batch verification LLM call failed: %v", err)
			// Mark all as inconclusive
			for i := range needsLLM {
				findings[needsLLMIndices[i]].VerificationStatus = "inconclusive"
				findings[needsLLMIndices[i]].VerificationReason = "LLM batch call failed"
			}
			return
		}

		// Apply batch results to findings
		if batchResult != nil {
			for _, result := range batchResult.BatchResults {
				if result.FindingIndex < len(needsLLM) {
					originalIdx := needsLLMIndices[result.FindingIndex]
					findings[originalIdx].VerificationStatus = result.Status
					findings[originalIdx].VerificationReason = result.Reasoning

					log.Printf(
						"ü§ñ LLM Result: Finding %d (%s) - %s (%.0f%% confidence)",
						originalIdx, findings[originalIdx].Title, result.Status, result.Confidence*100,
					)

					// Mark low confidence as likely_false
					if result.Confidence < 0.3 && result.Status != "verified" {
						findings[originalIdx].VerificationStatus = "likely_false"
						log.Printf("üî¥ Low confidence (%.2f), marking as likely false", result.Confidence)
					}
				}
			}
		}
	}

	log.Printf("‚úÖ Batch verification completed for %d findings", len(findings))
}

// filterFindingsForVerification –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ—Ç findings –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å
func (analyzer *GenkitSecurityAnalyzer) filterFindingsForVerification(
	findings []models.Finding,
	siteContext *models.SiteContext,
) []models.Finding {
	filtered := make([]models.Finding, 0, len(findings))

	for _, finding := range findings {
		// Check 1: If this pattern was already verified as safe, skip
		var patternKey string
		if len(finding.TestRequests) > 0 {
			patternKey = finding.TestRequests[0].URL + ":" + finding.Title
		} else {
			patternKey = finding.Title
		}
		if analyzer.contextManager.IsPatternVerifiedSafe(siteContext.Host, patternKey) {
			log.Printf("‚è≠Ô∏è  Skipping pre-verified safe pattern: %s", patternKey)
			finding.VerificationStatus = "likely_false"
			finding.VerificationReason = "Previously verified as safe"
			continue
		}

		// Check 2: If pattern was verified as vulnerable, mark it confirmed
		if analyzer.contextManager.IsPatternVerifiedVulnerable(siteContext.Host, patternKey) {
			log.Printf("‚è≠Ô∏è  Skipping pre-verified vulnerable pattern: %s", patternKey)
			finding.VerificationStatus = "confirmed"
			finding.VerificationReason = "Previously verified as vulnerable"
			continue
		}

		// Check 3: Skip if low impact + high effort
		if finding.Impact == "low" && finding.Effort == "high" {
			log.Printf("‚è≠Ô∏è  Skipping low-impact high-effort finding: %s", finding.Title)
			finding.VerificationStatus = "manual_check"
			finding.VerificationReason = "Effort too high for automated testing"
			continue
		}

		// Keep this finding for verification
		filtered = append(filtered, finding)
	}

	return filtered
}

// updateSiteContextWithVerification –æ–±–Ω–æ–≤–ª—è–µ—Ç SiteContext —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
func (analyzer *GenkitSecurityAnalyzer) updateSiteContextWithVerification(
	siteContext *models.SiteContext,
	findings []models.Finding,
) {
	for _, finding := range findings {
		var patternKey, testDesc string
		if len(finding.TestRequests) > 0 {
			patternKey = finding.TestRequests[0].URL + ":" + finding.Title
			testDesc = fmt.Sprintf("%s %s", finding.TestRequests[0].Method, finding.TestRequests[0].URL)
		} else {
			patternKey = finding.Title
			testDesc = finding.Title
		}

		if finding.VerificationStatus == "confirmed" || finding.VerificationStatus == "likely_true" {
			// Mark as vulnerable
			analyzer.contextManager.MarkPatternAsVulnerable(
				siteContext.Host,
				patternKey,
				finding.Impact,
				testDesc,
			)
		} else if finding.VerificationStatus == "likely_false" {
			// Mark as safe
			analyzer.contextManager.MarkPatternAsSafe(siteContext.Host, patternKey)
		}
	}

	log.Printf("üìö Updated SiteContext with %d verified patterns for %s", len(findings), siteContext.Host)
}

// executeTestRequest –≤—ã–ø–æ–ª–Ω—è–µ—Ç HTTP –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
func (analyzer *GenkitSecurityAnalyzer) executeTestRequest(
	ctx context.Context,
	testReq models.TestRequest,
	originalReq models.RequestResponseInfo,
) *models.TestResult {
	// Execute HTTP request
	verifyResult, err := analyzer.verificationClient.ExecuteTestRequest(ctx, testReq)
	if err != nil {
		log.Printf("‚ö†Ô∏è Test request failed: %v", err)
		return &models.TestResult{
			StatusCode:   0,
			ResponseBody: "",
			Error:        err.Error(),
		}
	}

	// Convert verification.TestResult to models.TestResult
	return &models.TestResult{
		StatusCode:   verifyResult.StatusCode,
		ResponseBody: verifyResult.ResponseBody,
		Headers:      verifyResult.Headers,
		Duration:     verifyResult.Duration,
		Error:        verifyResult.Error,
	}
}

// getOrCreateSiteContext –ø–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ö–æ—Å—Ç–∞.
func (analyzer *GenkitSecurityAnalyzer) getOrCreateSiteContext(host string) *models.SiteContext {
	return analyzer.contextManager.GetOrCreate(host)
}

func (analyzer *GenkitSecurityAnalyzer) prepareContentForLLM(content, contentType string) string {
	if len(content) == 0 {
		return "empty"
	}

	// –î–ª—è HTML –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–µ–≥–æ–≤ –∏ —Ä–∞–∑–º–µ—Ç–∫–∏, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ø–æ–Ω—è–ª–∞ —Å—É—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
	if strings.Contains(contentType, "html") {
		doc, err := goquery.NewDocumentFromReader(strings.NewReader(content))
		if err == nil {
			// –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∏ –Ω–µ –∑–∞–≥—Ä–æ–º–æ–∂–¥–∞–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
			doc.Find("script, style").Remove()
			// –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏–∑ body
			textContent := doc.Find("body").Text()
			// –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
			textContent = strings.Join(strings.Fields(textContent), " ")
			return llm.TruncateString("HTML Text Content: "+textContent, 2000) // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤
		}
	}

	// –î–ª—è JavaScript –∏ JSON –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ–º, —Ç.–∫. –∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–∂–Ω–∞
	if strings.Contains(contentType, "javascript") || strings.Contains(contentType, "json") {
		return llm.TruncateString(content, 2000) // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤
	}

	// –î–ª—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, text/plain) —Ç–æ–∂–µ –æ–±—Ä–µ–∑–∞–µ–º
	return llm.TruncateString(content, 3500)
}

// shouldExtractData –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è HTML/JS)
func (analyzer *GenkitSecurityAnalyzer) shouldExtractData(contentType, body string) bool {
	// –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ contentType (O(1))
	if strings.Contains(contentType, "html") {
		return true
	}
	if strings.Contains(contentType, "javascript") || strings.Contains(contentType, "json") {
		return true
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º body –¢–û–õ–¨–ö–û –µ—Å–ª–∏ contentType –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω
	if contentType == "" || contentType == "text/plain" {
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 1KB –≤–º–µ—Å—Ç–æ –≤—Å–µ–≥–æ body
		prefix := body
		if len(body) > 1024 {
			prefix = body[:1024]
		}
		return strings.Contains(prefix, "<html") || strings.Contains(prefix, "<!DOCTYPE")
	}

	return false
}

// –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å URL –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏

// updateURLPattern –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω URL —Å –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
func (analyzer *GenkitSecurityAnalyzer) updateURLPattern(
	siteContext *models.SiteContext, url, method string, urlAnalysisResp *models.URLAnalysisResponse,
) {
	if siteContext == nil || urlAnalysisResp == nil {
		return
	}

	// –ï—Å–ª–∏ –µ—Å—Ç—å URLNote –≤ –æ—Ç–≤–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
	if urlAnalysisResp.URLNote != nil {
		analyzer.contextManager.UpdateURLPattern(siteContext, url, method, urlAnalysisResp.URLNote)
	} else {
		// –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–µ–º –∑–∞–º–µ—Ç–∫—É –∏–∑ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–µ–π
		note := &models.URLNote{
			Content:    urlAnalysisResp.EndpointType,
			Suspicious: urlAnalysisResp.InterestLevel == "high",
			Confidence: 0.5, // default confidence
		}
		analyzer.contextManager.UpdateURLPattern(siteContext, url, method, note)
	}
}

// GenerateHypothesisForHost –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É –¥–ª—è —Ö–æ—Å—Ç–∞
func (analyzer *GenkitSecurityAnalyzer) GenerateHypothesisForHost(host string) (*models.HypothesisResponse, error) {
	return analyzer.hypothesisGen.GenerateForHost(host)
}

// verifyHypothesis –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É –æ–± —É—è–∑–≤–∏–º–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é LLM
func (analyzer *GenkitSecurityAnalyzer) verifyHypothesis(
	ctx context.Context,
	req *models.VerificationRequest,
	hypothesis string,
) (*models.VerificationResponse, error) {
	log.Printf("üî¨ Starting verification for: %s", hypothesis)

	// –®–∞–≥ 1: LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–∏–ø–æ—Ç–µ–∑—ã
	prompt := analyzer.buildVerificationPrompt(req, hypothesis)

	llmResponse, err := analyzer.llmProvider.GenerateVerificationPlan(
		ctx, &models.VerificationPlanRequest{
			Hypothesis:      hypothesis,
			OriginalRequest: req.OriginalRequest,
			MaxAttempts:     req.MaxAttempts,
			TargetURL:       req.OriginalRequest.URL,
			AdditionalInfo:  prompt,
		},
	)

	if err != nil {
		return &models.VerificationResponse{
			Status:            "inconclusive",
			UpdatedConfidence: 0.5,
			Reasoning:         fmt.Sprintf("Failed to generate verification plan: %v", err),
			TestAttempts:      []models.TestAttempt{},
		}, nil
	}

	// –®–∞–≥ 2: –í—ã–ø–æ–ª–Ω—è–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
	var testAttempts []models.TestAttempt
	var successfulTests []models.TestAttempt

	for _, testReq := range llmResponse.TestRequests {
		// –ò—Å–ø–æ–ª—å–∑—É–µ–º models.TestRequest –Ω–∞–ø—Ä—è–º—É—é
		verificationReq := models.TestRequest{
			URL:     testReq.URL,
			Method:  testReq.Method,
			Headers: testReq.Headers,
			Body:    testReq.Body,
		}

		// –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
		testResp, err := analyzer.verificationClient.MakeRequest(ctx, verificationReq)

		testAttempt := models.TestAttempt{
			RequestURL:    testReq.URL,
			RequestMethod: testReq.Method,
			Headers:       make(map[string]string),
		}

		if err != nil {
			testAttempt.Error = err.Error()
			testAttempt.StatusCode = 0
			log.Printf("‚ùå Test request failed: %s - %v", testReq.URL, err)
		} else {
			testAttempt.StatusCode = testResp.StatusCode
			testAttempt.ResponseSize = testResp.ResponseSize
			testAttempt.ResponseBody = testResp.ResponseBody
			testAttempt.Headers = testResp.Headers
			testAttempt.Duration = testResp.Duration.String()
			successfulTests = append(successfulTests, testAttempt)
			log.Printf("‚úÖ Test request completed: %s - Status: %d", testReq.URL, testResp.StatusCode)
		}

		testAttempts = append(testAttempts, testAttempt)
	}

	// –®–∞–≥ 3: LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
	analysisResponse, err := analyzer.llmProvider.AnalyzeVerificationResults(
		ctx, &models.VerificationAnalysisRequest{
			Hypothesis:         hypothesis,
			OriginalConfidence: 0.5, // Default initial confidence
			TestResults:        successfulTests,
			OriginalRequest:    req.OriginalRequest,
		},
	)

	if err != nil {
		return &models.VerificationResponse{
			Status:            "inconclusive",
			UpdatedConfidence: 0.5,
			Reasoning:         fmt.Sprintf("Failed to analyze verification results: %v", err),
			TestAttempts:      testAttempts,
		}, nil
	}

	log.Printf("üéØ Verification completed: %s - Status: %s", hypothesis, analysisResponse.Status)

	return &models.VerificationResponse{
		Status:            analysisResponse.Status,
		UpdatedConfidence: analysisResponse.UpdatedConfidence,
		Reasoning:         analysisResponse.Reasoning,
		TestAttempts:      testAttempts,
		RecommendedPOC:    analysisResponse.RecommendedPOC,
	}, nil
}

// buildVerificationPrompt —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
func (analyzer *GenkitSecurityAnalyzer) buildVerificationPrompt(
	req *models.VerificationRequest,
	hypothesis string,
) string {
	return fmt.Sprintf(
		`You are a security verification assistant. Your task is to verify a security hypothesis by generating and analyzing test requests.

HYPOTHESIS TO VERIFY: %s
TARGET: %s

ORIGINAL REQUEST DETAILS:
- Method: %s
- URL: %s
- Status Code: %d
- Response Size: %d bytes

VERIFICATION REQUIREMENTS:
1. Generate %d test requests to verify this hypothesis
2. Each request should target the specific vulnerability type suggested
3. Focus on non-destructive testing that demonstrates the vulnerability
4. Include variations in parameters, payloads, or endpoints as appropriate
5. Consider both positive (vulnerable) and negative (secure) test cases

Generate targeted test requests that can definitively prove or disprove this security hypothesis.`,
		hypothesis,
		req.OriginalRequest.URL,
		req.OriginalRequest.Method,
		req.OriginalRequest.URL,
		req.OriginalRequest.StatusCode,
		len(req.OriginalRequest.RespBody),
		req.MaxAttempts,
	)
}

// GetSiteContext –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ö–æ—Å—Ç–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
func (analyzer *GenkitSecurityAnalyzer) GetSiteContext(host string) *models.SiteContext {
	return analyzer.contextManager.Get(host)
}

// priorityScore –≤—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç finding –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
// –í—ã—à–µ impact = –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –Ω–∏–∂–µ effort = –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
func priorityScore(f models.Finding) int {
	impactScores := map[string]int{"critical": 40, "high": 30, "medium": 20, "low": 10}
	effortScores := map[string]int{"low": 3, "medium": 2, "high": 1}

	impactScore := impactScores[f.Impact]
	if impactScore == 0 {
		impactScore = 10 // default
	}

	effortScore := effortScores[f.Effort]
	if effortScore == 0 {
		effortScore = 1 // default
	}

	return impactScore + effortScore
}
