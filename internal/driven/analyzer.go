package driven

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"regexp"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/BetterCallFirewall/Hackerecon/internal/llm"
	"github.com/BetterCallFirewall/Hackerecon/internal/models"
	"github.com/BetterCallFirewall/Hackerecon/internal/utils"
	"github.com/BetterCallFirewall/Hackerecon/internal/websocket"
	"github.com/PuerkitoBio/goquery"
	"github.com/firebase/genkit/go/ai"
	genkitcore "github.com/firebase/genkit/go/core"
	"github.com/firebase/genkit/go/genkit"
	"github.com/google/uuid"
)

var urlRegexes = []*regexp.Regexp{
	regexp.MustCompile(`https?://[a-zA-Z0-9\-._~:/?#[\]@!$&'()*+,;=%]+`),
	regexp.MustCompile(`/api/[a-zA-Z0-9\-._~:/?#[\]@!$&'()*+,;=%]*`),
	regexp.MustCompile(`/v[0-9]+/[a-zA-Z0-9\-._~:/?#[\]@!$&'()*+,;=%]*`),
}

// GenkitSecurityAnalyzer –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Genkit
type GenkitSecurityAnalyzer struct {
	model          string
	llmProvider    llm.Provider // –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è generic)
	WsHub          *websocket.WebsocketManager
	genkitApp      *genkit.Genkit
	mutex          sync.RWMutex
	reports        []models.VulnerabilityReport
	secretPatterns []*regexp.Regexp
	analysisFlow   *genkitcore.Flow[*models.SecurityAnalysisRequest, *models.SecurityAnalysisResponse, struct{}]

	// –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
	siteContexts map[string]*models.SiteContext
	contextMutex sync.RWMutex

	// –ù–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
	urlNormalizer   *utils.ContextAwareNormalizer
	requestFilter   *utils.RequestFilter
	techDetector    *utils.TechDetector
	urlAnalysisFlow *genkitcore.Flow[*models.URLAnalysisRequest, *models.URLAnalysisResponse, struct{}]
	hypothesisFlow  *genkitcore.Flow[*models.HypothesisRequest, *models.HypothesisResponse, struct{}]

	// –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
	analysisCache map[string]*CachedAnalysis
	cacheMutex    sync.RWMutex
	cacheExpiry   time.Duration

	// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
	stats struct {
		totalRequests       int64
		filteredRequests    int64
		quickAnalyses       int64
		fullAnalyses        int64
		cacheHits           int64
		hypothesisGenerated int64
	}
}

// CachedAnalysis –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
type CachedAnalysis struct {
	URLPattern     string
	Method         string
	LastAnalyzed   time.Time
	AnalysisResult *models.URLAnalysisResponse
	AccessCount    int
	Confidence     float64
}

// newGenkitSecurityAnalyzer —Å–æ–∑–¥–∞—ë—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å Gemini (–±–µ–∑ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞)
func newGenkitSecurityAnalyzer(genkitApp *genkit.Genkit, model string, wsHub *websocket.WebsocketManager) (
	*GenkitSecurityAnalyzer, error,
) {
	return newSecurityAnalyzerWithProvider(genkitApp, model, nil, wsHub)
}

// newSecurityAnalyzerWithProvider —Å–æ–∑–¥–∞—ë—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∫–∞—Å—Ç–æ–º–Ω—ã–º LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º
// –ï—Å–ª–∏ provider == nil, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Gemini —á–µ—Ä–µ–∑ Genkit
func newSecurityAnalyzerWithProvider(
	genkitApp *genkit.Genkit,
	model string,
	provider llm.Provider,
	wsHub *websocket.WebsocketManager,
) (*GenkitSecurityAnalyzer, error) {
	analyzer := &GenkitSecurityAnalyzer{
		model:          model,
		llmProvider:    provider,
		WsHub:          wsHub,
		genkitApp:      genkitApp,
		reports:        make([]models.VulnerabilityReport, 0),
		secretPatterns: createSecretRegexPatterns(),
		siteContexts:   make(map[string]*models.SiteContext),

		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
		urlNormalizer: utils.NewContextAwareNormalizer(),
		requestFilter: utils.NewRequestFilter(),
		techDetector:  utils.NewTechDetector(),
		analysisCache: make(map[string]*CachedAnalysis),
		cacheExpiry:   10 * time.Minute,
	}

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º flow –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
	analyzer.analysisFlow = genkit.DefineFlow(
		genkitApp, "securityAnalysisFlow",
		func(ctx context.Context, req *models.SecurityAnalysisRequest) (*models.SecurityAnalysisResponse, error) {
			return analyzer.performSecurityAnalysis(ctx, req)
		},
	)

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º flow –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏ URL
	analyzer.urlAnalysisFlow = genkit.DefineFlow(
		genkitApp, "urlAnalysisFlow",
		func(ctx context.Context, req *models.URLAnalysisRequest) (*models.URLAnalysisResponse, error) {
			return analyzer.performURLAnalysis(ctx, req)
		},
	)

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º flow –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–∏–ø–æ—Ç–µ–∑
	analyzer.hypothesisFlow = genkit.DefineFlow(
		genkitApp, "hypothesisFlow",
		func(ctx context.Context, req *models.HypothesisRequest) (*models.HypothesisResponse, error) {
			return analyzer.performHypothesisGeneration(ctx, req)
		},
	)

	return analyzer, nil
}

// performSecurityAnalysis –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é Genkit –∏–ª–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
func (analyzer *GenkitSecurityAnalyzer) performSecurityAnalysis(
	ctx context.Context, req *models.SecurityAnalysisRequest,
) (*models.SecurityAnalysisResponse, error) {
	var result *models.SecurityAnalysisResponse
	var err error

	// –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
	if analyzer.llmProvider != nil {
		result, err = analyzer.llmProvider.GenerateSecurityAnalysis(ctx, req)
		if err != nil {
			return nil, fmt.Errorf("failed to generate security analysis: %w", err)
		}
	} else {
		// –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º Genkit (Gemini)
		prompt := analyzer.buildSecurityAnalysisPrompt(req)

		result, _, err = genkit.GenerateData[models.SecurityAnalysisResponse](
			ctx, analyzer.genkitApp,
			ai.WithPrompt(prompt),
		)

		if err != nil {
			return nil, fmt.Errorf("failed to generate security analysis: %w", err)
		}
	}

	// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º timestamp –∏ URL
	result.Timestamp = time.Now()

	// –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º risk_level –∫ lowercase (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ LLM –≤–µ—Ä–Ω—É–ª "Low" –≤–º–µ—Å—Ç–æ "low")
	result.RiskLevel = strings.ToLower(strings.TrimSpace(result.RiskLevel))

	// –í–∞–ª–∏–¥–∏—Ä—É–µ–º risk_level
	validRiskLevels := map[string]bool{"low": true, "medium": true, "high": true, "critical": true}
	if !validRiskLevels[result.RiskLevel] {
		log.Printf("‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π risk_level '%s', —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 'low'", result.RiskLevel)
		result.RiskLevel = "low"
	}

	// –î–æ–ø–æ–ª–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ —Å–µ–∫—Ä–µ—Ç–∞–º–∏
	result.ExtractedSecrets = append(result.ExtractedSecrets, req.ExtractedData.APIKeys...)
	result.ExtractedSecrets = append(result.ExtractedSecrets, req.ExtractedData.Secrets...)

	return result, nil
}

// AnalyzeHTTPTraffic –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTTP —Ç—Ä–∞—Ñ–∏–∫ —Å –ø–æ–º–æ—â—å—é Genkit flows
// AnalyzeHTTPTraffic –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ HTTP —Ç—Ä–∞—Ñ–∏–∫–∞ —Å –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
func (analyzer *GenkitSecurityAnalyzer) AnalyzeHTTPTraffic(
	ctx context.Context, req *http.Request, resp *http.Response, reqBody, respBody, contentType string,
) (*models.VulnerabilityReport, error) {
	// –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
	atomic.AddInt64(&analyzer.stats.totalRequests, 1)

	// 1. –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
	shouldSkip, reason := analyzer.requestFilter.ShouldSkipRequestWithReason(req, resp, contentType)
	if shouldSkip {
		atomic.AddInt64(&analyzer.stats.filteredRequests, 1)
		log.Printf("‚ö™Ô∏è –ü—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ %s %s: %s", req.Method, req.URL.String(), reason)
		return nil, nil // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
	}

	log.Printf("üîç –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: %s %s (Content-Type: %s)", req.Method, req.URL.String(), contentType)

	// 2. –ü–æ–ª—É—á–∞–µ–º/—Å–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–∞–π—Ç–∞
	siteContext := analyzer.getOrCreateSiteContext(req.URL.Host)

	// 3. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å—Ç–µ–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)
	if siteContext.TechStack == nil {
		techStack := analyzer.techDetector.DetectFromRequest(req, resp, respBody)
		siteContext.TechStack = techStack
		siteContext.LastUpdated = time.Now()
	}

	// 4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL
	normalizedURL := analyzer.urlNormalizer.NormalizeWithContext(req.URL.String())
	cacheKey := fmt.Sprintf("%s:%s", req.Method, normalizedURL)

	// 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
	if cached := analyzer.getCachedAnalysis(cacheKey); cached != nil {
		// –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
		analyzer.updateCachedAnalysis(cacheKey, cached)
		atomic.AddInt64(&analyzer.stats.cacheHits, 1)

		// –ï—Å–ª–∏ –≤—ã—Å–æ–∫–∏–π confidence –∏ –Ω–µ–¥–∞–≤–Ω–∏–π –∞–Ω–∞–ª–∏–∑ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
		if time.Since(cached.LastAnalyzed) < 5*time.Minute && cached.Confidence > 0.8 {
			log.Printf("üì¶ –ü—Ä–æ–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ %s - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (confidence: %.2f, –≤–æ–∑—Ä–∞—Å—Ç: %v)",
				cacheKey, cached.Confidence, time.Since(cached.LastAnalyzed))
			return nil, nil
		} else {
			log.Printf("üì¶ –ù–∞–π–¥–µ–Ω –∫—ç—à –¥–ª—è %s, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (confidence: %.2f, –≤–æ–∑—Ä–∞—Å—Ç: %v)",
				cacheKey, cached.Confidence, time.Since(cached.LastAnalyzed))
		}
	} else {
		log.Printf("üÜï –ù–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: %s", cacheKey)
	}

	// 6. –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑

	// –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ URL
	urlAnalysisReq := &models.URLAnalysisRequest{
		NormalizedURL: normalizedURL,
		Method:        req.Method,
		Headers:       convertHeaders(req.Header),
		ResponseBody:  analyzer.prepareContentForLLM(respBody, contentType),
		ContentType:   contentType,
		SiteContext:   siteContext,
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑
	urlAnalysisResp, err := analyzer.urlAnalysisFlow.Run(ctx, urlAnalysisReq)
	if err != nil {
		log.Printf("‚ùå Failed quick URL analysis: %v", err)
		// –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, fallback –Ω–∞ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
		return analyzer.fallbackFullAnalysis(ctx, req, resp, reqBody, respBody, contentType, siteContext)
	}

	atomic.AddInt64(&analyzer.stats.quickAnalyses, 1)

	// 7. –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏
	analyzer.cacheAnalysis(cacheKey, urlAnalysisResp)

	// 8. –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω URL —Å –∑–∞–º–µ—Ç–∫–∞–º–∏ –æ—Ç LLM
	analyzer.updateURLPattern(siteContext, normalizedURL, req.Method, urlAnalysisResp.URLNote)

	// 9. –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
	if urlAnalysisResp.ShouldAnalyze {
		log.Printf("üî¨ –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è %s (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: %s, –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: %v)",
			cacheKey, urlAnalysisResp.Priority, urlAnalysisResp.URLNote.Suspicious)

		report, err := analyzer.fullSecurityAnalysis(ctx, req, resp, reqBody, respBody, contentType, siteContext, urlAnalysisResp.URLNote)
		if err != nil {
			log.Printf("‚ùå Failed full security analysis: %v", err)
			return nil, err
		}

		atomic.AddInt64(&analyzer.stats.fullAnalyses, 1)
		return report, nil
	} else {
		log.Printf("‚úÖ –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è %s: %s (confidence: %.2f, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: %s)",
			cacheKey, urlAnalysisResp.URLNote.Content, urlAnalysisResp.URLNote.Confidence, urlAnalysisResp.Priority)
	}

	// –£–î–ê–õ–ï–ù–û: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑
	// –ì–∏–ø–æ—Ç–µ–∑—ã —Ç–µ–ø–µ—Ä—å –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ API

	// –ï—Å–ª–∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –Ω—É–∂–µ–Ω, –Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
	analyzer.updateSiteContextWithURLNote(siteContext, req.URL.String(), urlAnalysisResp.URLNote)

	return nil, nil
}

// fallbackFullAnalysis —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
func (analyzer *GenkitSecurityAnalyzer) fallbackFullAnalysis(
	ctx context.Context,
	req *http.Request,
	resp *http.Response,
	reqBody, respBody, contentType string,
	siteContext *models.SiteContext,
) (*models.VulnerabilityReport, error) {
	// –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
	extractedData := analyzer.extractDataFromContent(reqBody, respBody, contentType)
	preparedRequestBody := analyzer.prepareContentForLLM(reqBody, req.Header.Get("Content-Type"))
	preparedResponseBody := analyzer.prepareContentForLLM(respBody, contentType)

	// –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
	analysisReq := &models.SecurityAnalysisRequest{
		URL:           req.URL.String(),
		Method:        req.Method,
		Headers:       convertHeaders(req.Header),
		RequestBody:   preparedRequestBody,
		ResponseBody:  preparedResponseBody,
		ContentType:   contentType,
		ExtractedData: *extractedData,
		SiteContext:   siteContext,
	}

	// –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
	result, err := analyzer.analysisFlow.Run(ctx, analysisReq)
	if err != nil {
		return nil, fmt.Errorf("security analysis failed: %w", err)
	}

	return analyzer.createVulnerabilityReport(req, resp, result, time.Now(), reqBody, respBody)
}

// fullSecurityAnalysis –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
func (analyzer *GenkitSecurityAnalyzer) fullSecurityAnalysis(
	ctx context.Context,
	req *http.Request,
	resp *http.Response,
	reqBody, respBody, contentType string,
	siteContext *models.SiteContext,
	urlNote *models.URLNote,
) (*models.VulnerabilityReport, error) {
	startTime := time.Now()

	// –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
	extractedData := analyzer.extractDataFromContent(reqBody, respBody, contentType)
	preparedRequestBody := analyzer.prepareContentForLLM(reqBody, req.Header.Get("Content-Type"))
	preparedResponseBody := analyzer.prepareContentForLLM(respBody, contentType)

	// –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
	analysisReq := &models.SecurityAnalysisRequest{
		URL:           req.URL.String(),
		Method:        req.Method,
		Headers:       convertHeaders(req.Header),
		RequestBody:   preparedRequestBody,
		ResponseBody:  preparedResponseBody,
		ContentType:   contentType,
		ExtractedData: *extractedData,
		SiteContext:   siteContext,
	}

	// –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –∑–∞–º–µ—Ç–∫–∏ –æ URL
	var result *models.SecurityAnalysisResponse
	var err error

	// –ò—Å–ø–æ–ª—å–∑—É–µ–º Genkit flow (–ø–æ–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞)
	result, err = analyzer.analysisFlow.Run(ctx, analysisReq)

	if err != nil {
		return nil, fmt.Errorf("full security analysis failed: %w", err)
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
	analyzer.updateSiteContext(req.URL.Host, req.URL.String(), result)

	return analyzer.createVulnerabilityReport(req, resp, result, startTime, reqBody, respBody)
}

// createVulnerabilityReport —Å–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç –æ–± —É—è–∑–≤–∏–º–æ—Å—Ç–∏
func (analyzer *GenkitSecurityAnalyzer) createVulnerabilityReport(
	req *http.Request,
	resp *http.Response,
	result *models.SecurityAnalysisResponse,
	startTime time.Time,
	reqBody, respBody string,
) (*models.VulnerabilityReport, error) {
	// –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
	report := &models.VulnerabilityReport{
		ID:             generateReportID(),
		Timestamp:      time.Now(),
		AnalysisResult: *result,
		ProcessingTime: time.Since(startTime),
	}

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
	analyzer.mutex.Lock()
	analyzer.reports = append(analyzer.reports, *report)
	analyzer.mutex.Unlock()

	// –õ–æ–≥–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏
	if result.HasVulnerability && (result.RiskLevel == "high" || result.RiskLevel == "critical") {
		log.Printf(
			"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –£–Ø–ó–í–ò–ú–û–°–¢–¨: %s - Risk: %s",
			req.URL.String(), result.RiskLevel,
		)
		log.Printf("üí° AI –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: %s", result.AIComment)

		// –õ–æ–≥–∏—Ä—É–µ–º —á–µ–∫–ª–∏—Å—Ç –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
		if len(result.SecurityChecklist) > 0 {
			log.Printf("üìã –í–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ (%d):", len(result.SecurityChecklist))
			for i, check := range result.SecurityChecklist {
				log.Printf("   ‚î£‚îÅ –¢–µ—Å—Ç %d: %s", i+1, check.Action)
				log.Printf("   ‚îÉ  –ß—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å: %s", check.Description)
				log.Printf("   ‚îó‚îÅ –û–∂–∏–¥–∞–µ—Ç—Å—è: %s", check.Expected)
				if i < len(result.SecurityChecklist)-1 {
					log.Println("   ‚îÉ")
				}
			}
		}
	}

	dto := models.ReportDTO{
		Report: *report,
		RequestResponse: models.RequestResponseInfo{
			URL:         req.URL.String(),
			Method:      req.Method,
			StatusCode:  resp.StatusCode,
			ReqHeaders:  convertHeaders(req.Header),
			RespHeaders: convertHeaders(resp.Header),
			ReqBody:     truncateString(reqBody, 2000),  // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤
			RespBody:    truncateString(respBody, 2000), // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤
		},
	}

	analyzer.WsHub.Broadcast(dto)

	return report, nil
}

func (analyzer *GenkitSecurityAnalyzer) getOrCreateSiteContext(host string) *models.SiteContext {
	analyzer.contextMutex.Lock()
	defer analyzer.contextMutex.Unlock()

	if context, exists := analyzer.siteContexts[host]; exists {
		return context
	}

	newContext := models.NewSiteContext(host)
	analyzer.siteContexts[host] = newContext
	return newContext
}

func (analyzer *GenkitSecurityAnalyzer) prepareContentForLLM(content, contentType string) string {
	if len(content) == 0 {
		return "empty"
	}

	// –î–ª—è HTML –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–µ–≥–æ–≤ –∏ —Ä–∞–∑–º–µ—Ç–∫–∏, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ø–æ–Ω—è–ª–∞ —Å—É—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
	if strings.Contains(contentType, "html") {
		doc, err := goquery.NewDocumentFromReader(strings.NewReader(content))
		if err == nil {
			// –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∏ –Ω–µ –∑–∞–≥—Ä–æ–º–æ–∂–¥–∞–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
			doc.Find("script, style").Remove()
			// –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏–∑ body
			textContent := doc.Find("body").Text()
			// –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
			re := regexp.MustCompile(`\s+`)
			textContent = re.ReplaceAllString(textContent, " ")
			return truncateString("HTML Text Content: "+textContent, 2000) // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤
		}
	}

	// –î–ª—è JavaScript –∏ JSON –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ–º, —Ç.–∫. –∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–∂–Ω–∞
	if strings.Contains(contentType, "javascript") || strings.Contains(contentType, "json") {
		return truncateString(content, 2000) // –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤
	}

	// –î–ª—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, text/plain) —Ç–æ–∂–µ –æ–±—Ä–µ–∑–∞–µ–º
	return truncateString(content, 1000)
}

// updateSiteContext –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM
func (analyzer *GenkitSecurityAnalyzer) updateSiteContext(
	host string, url string,
	llmResponse *models.SecurityAnalysisResponse,
) {
	analyzer.contextMutex.Lock()
	defer analyzer.contextMutex.Unlock()

	context, exists := analyzer.siteContexts[host]
	if !exists {
		return // –î–æ–ª–∂–µ–Ω —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º —Ä–æ–ª–∏
	if llmResponse.IdentifiedUserRole != "" {
		context.UserRoles[llmResponse.IdentifiedUserRole] = true
	}

	// –ò–ó–ú–ï–ù–ï–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–∞–Ω–Ω—ã—Ö, –∏—Ç–µ—Ä–∏—Ä—É—è—Å—å –ø–æ —Å—Ä–µ–∑—É
	if len(llmResponse.IdentifiedDataObjects) > 0 {
		for _, dataObject := range llmResponse.IdentifiedDataObjects {
			name := dataObject.Name
			fields := dataObject.Fields
			if name == "" || len(fields) == 0 {
				continue
			}

			// –õ–æ–≥–∏–∫–∞ —Å–ª–∏—è–Ω–∏—è –ø–æ–ª–µ–π –æ—Å—Ç–∞–µ—Ç—Å—è —Ç–æ–π –∂–µ
			existingFields := make(map[string]bool)
			for _, field := range context.DataObjects[name] {
				existingFields[field] = true
			}
			for _, newField := range fields {
				if !existingFields[newField] {
					context.DataObjects[name] = append(context.DataObjects[name], newField)
				}
			}
		}
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
	context.DiscoveredEndpoints[url] = true
	context.LastUpdated = time.Now()
}

// extractDataFromContent –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ HTTP –∫–æ–Ω—Ç–µ–Ω—Ç–∞
func (analyzer *GenkitSecurityAnalyzer) extractDataFromContent(reqBody, respBody, contentType string) *models.ExtractedData {
	extractedData := &models.ExtractedData{
		URLs:          make([]string, 0),
		APIKeys:       make([]models.ExtractedSecret, 0),
		Secrets:       make([]models.ExtractedSecret, 0),
		JSFunctions:   make([]models.JSFunction, 0),
		FormActions:   make([]string, 0),
		Comments:      make([]string, 0),
		ExternalHosts: make([]string, 0),
	}

	contents := []string{reqBody, respBody}
	locations := []string{"request", "response"}

	for i, content := range contents {
		if content == "" {
			continue
		}

		location := locations[i]

		// –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–∫—Ä–µ—Ç—ã
		secrets := analyzer.extractSecretsFromContent(content, location)
		extractedData.APIKeys = append(extractedData.APIKeys, secrets...)

		// –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º JavaScript –∫–æ–Ω—Ç–µ–Ω—Ç
		if strings.Contains(contentType, "javascript") ||
			strings.Contains(content, "function") ||
			strings.Contains(content, "const ") ||
			strings.Contains(content, "var ") {

			jsFunctions := analyzer.extractJavaScriptFunctions(content)
			extractedData.JSFunctions = append(extractedData.JSFunctions, jsFunctions...)

			urls := analyzer.extractURLsFromJS(content)
			extractedData.URLs = append(extractedData.URLs, urls...)
		}

		// –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º HTML –∫–æ–Ω—Ç–µ–Ω—Ç
		if strings.Contains(contentType, "html") ||
			strings.Contains(content, "<html") ||
			strings.Contains(content, "<!DOCTYPE") {

			htmlData := analyzer.extractHTMLData(content)
			extractedData.FormActions = append(extractedData.FormActions, htmlData.FormActions...)
			extractedData.Comments = append(extractedData.Comments, htmlData.Comments...)
			extractedData.URLs = append(extractedData.URLs, htmlData.URLs...)
		}
	}

	return extractedData
}

// extractSecretsFromContent –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ–∫—Ä–µ—Ç—ã —Å –ø–æ–º–æ—â—å—é regex
func (analyzer *GenkitSecurityAnalyzer) extractSecretsFromContent(content, location string) []models.ExtractedSecret {
	secrets := make([]models.ExtractedSecret, 0)

	for _, pattern := range analyzer.secretPatterns {
		matches := pattern.FindAllStringSubmatch(content, -1)
		for _, match := range matches {
			if len(match) >= 3 {
				secretType := identifySecretType(match[0])
				secretValue := strings.Trim(match[2], `"'`)

				if len(secretValue) < 8 {
					continue
				}

				secrets = append(
					secrets, models.ExtractedSecret{
						Type:       secretType,
						Value:      truncateSecret(secretValue),
						Context:    truncateString(match[0], 100),
						Confidence: calculateSecretConfidence(secretType, secretValue),
						Location:   location,
					},
				)
			}
		}
	}

	return secrets
}

// extractJavaScriptFunctions –∏–∑–≤–ª–µ–∫–∞–µ—Ç JavaScript —Ñ—É–Ω–∫—Ü–∏–∏
func (analyzer *GenkitSecurityAnalyzer) extractJavaScriptFunctions(content string) []models.JSFunction {
	functions := make([]models.JSFunction, 0)

	funcRegex := regexp.MustCompile(`function\s+([a-zA-Z_$][a-zA-Z0-9_$]*)\s*\(([^)]*)\)`)
	matches := funcRegex.FindAllStringSubmatch(content, -1)

	for _, match := range matches {
		if len(match) >= 3 {
			funcName := match[1]
			params := strings.Split(strings.TrimSpace(match[2]), ",")

			// –û—á–∏—â–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
			for i, param := range params {
				params[i] = strings.TrimSpace(param)
			}

			suspicious, reason := isSuspiciousFunction(funcName, content)

			functions = append(
				functions, models.JSFunction{
					Name:       funcName,
					Parameters: params,
					Context:    truncateString(match[0], 200),
					Suspicious: suspicious,
					Reason:     reason,
				},
			)
		}
	}

	return functions
}

// extractURLsFromJS –∏–∑–≤–ª–µ–∫–∞–µ—Ç URL'—ã –∏–∑ JavaScript
func (analyzer *GenkitSecurityAnalyzer) extractURLsFromJS(content string) []string {
	urls := make([]string, 0)

	for _, regex := range urlRegexes {
		matches := regex.FindAllString(content, -1)
		urls = append(urls, matches...)
	}

	return removeDuplicates(urls)
}

// extractHTMLData –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML —Å –ø–æ–º–æ—â—å—é goquery
func (analyzer *GenkitSecurityAnalyzer) extractHTMLData(content string) *models.HTMLData {
	data := &models.HTMLData{
		FormActions: make([]string, 0),
		Comments:    make([]string, 0),
		URLs:        make([]string, 0),
	}

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(content))
	if err != nil {
		return data
	}

	// –ò–∑–≤–ª–µ–∫–∞–µ–º form actions
	doc.Find("form[action]").Each(
		func(i int, s *goquery.Selection) {
			if action, exists := s.Attr("action"); exists && action != "#" {
				data.FormActions = append(data.FormActions, action)
			}
		},
	)

	// –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏
	doc.Find("a[href], script[src], img[src], iframe[src]").Each(
		func(i int, s *goquery.Selection) {
			if href, exists := s.Attr("href"); exists && href != "#" {
				data.URLs = append(data.URLs, href)
			}
			if src, exists := s.Attr("src"); exists {
				data.URLs = append(data.URLs, src)
			}
		},
	)

	// –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
	commentRegex := regexp.MustCompile(`<!--(.*?)-->`)
	comments := commentRegex.FindAllStringSubmatch(content, -1)
	for _, match := range comments {
		if len(match) >= 2 {
			comment := strings.TrimSpace(match[1])
			if len(comment) > 5 && !strings.HasPrefix(comment, "<!") {
				data.Comments = append(data.Comments, truncateString(comment, 200))
			}
		}
	}

	return data
}

// GetReports –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –æ—Ç—á–µ—Ç—ã
func (analyzer *GenkitSecurityAnalyzer) GetReports() []models.VulnerabilityReport {
	analyzer.mutex.RLock()
	defer analyzer.mutex.RUnlock()

	reports := make([]models.VulnerabilityReport, len(analyzer.reports))
	copy(reports, analyzer.reports)
	return reports
}

// GetHighRiskReports –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–æ—Ä–∏—Å–∫–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã
func (analyzer *GenkitSecurityAnalyzer) GetHighRiskReports() []models.VulnerabilityReport {
	analyzer.mutex.RLock()
	defer analyzer.mutex.RUnlock()

	highRiskReports := make([]models.VulnerabilityReport, 0)
	for _, report := range analyzer.reports {
		if report.AnalysisResult.HasVulnerability &&
			(report.AnalysisResult.RiskLevel == "high" || report.AnalysisResult.RiskLevel == "critical") {
			highRiskReports = append(highRiskReports, report)
		}
	}
	return highRiskReports
}

// GetSummaryStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞
func (analyzer *GenkitSecurityAnalyzer) GetSummaryStats() map[string]interface{} {
	analyzer.mutex.RLock()
	defer analyzer.mutex.RUnlock()

	stats := map[string]interface{}{
		"total_reports":       len(analyzer.reports),
		"vulnerable_requests": 0,
		"critical_risks":      0,
		"high_risks":          0,
		"medium_risks":        0,
		"low_risks":           0,
		"secrets_found":       0,
		"avg_confidence":      0.0,
		"vulnerability_types": make(map[string]int),
	}

	totalConfidence := 0.0
	totalSecrets := 0

	for _, report := range analyzer.reports {
		if report.AnalysisResult.HasVulnerability {
			stats["vulnerable_requests"] = stats["vulnerable_requests"].(int) + 1

			switch report.AnalysisResult.RiskLevel {
			case "critical":
				stats["critical_risks"] = stats["critical_risks"].(int) + 1
			case "high":
				stats["high_risks"] = stats["high_risks"].(int) + 1
			case "medium":
				stats["medium_risks"] = stats["medium_risks"].(int) + 1
			case "low":
				stats["low_risks"] = stats["low_risks"].(int) + 1
			}

			for _, vulnType := range report.AnalysisResult.VulnerabilityTypes {
				count := stats["vulnerability_types"].(map[string]int)[vulnType]
				stats["vulnerability_types"].(map[string]int)[vulnType] = count + 1
			}
		}

		totalConfidence += report.AnalysisResult.ConfidenceScore
		totalSecrets += len(report.AnalysisResult.ExtractedSecrets)
	}

	stats["secrets_found"] = totalSecrets
	if len(analyzer.reports) > 0 {
		stats["avg_confidence"] = totalConfidence / float64(len(analyzer.reports))
	}

	return stats
}

// (removed duplicate GenerateHypothesisForHost; single implementation exists later in file)

// –ù–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

// performURLAnalysis –≤—ã–ø–æ–ª–Ω—è–µ—Ç –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ URL
func (analyzer *GenkitSecurityAnalyzer) performURLAnalysis(
	ctx context.Context, req *models.URLAnalysisRequest,
) (*models.URLAnalysisResponse, error) {
	var result *models.URLAnalysisResponse
	var err error

	// –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
	if analyzer.llmProvider != nil {
		result, err = analyzer.llmProvider.GenerateURLAnalysis(ctx, req)
		if err != nil {
			return nil, fmt.Errorf("failed to generate URL analysis: %w", err)
		}
	} else {
		// –ò—Å–ø–æ–ª—å–∑—É–µ–º Genkit –¥–ª—è Gemini
		prompt := llm.BuildURLAnalysisPrompt(req)
		result, _, err = genkit.GenerateData[models.URLAnalysisResponse](
			ctx, analyzer.genkitApp,
			ai.WithPrompt(prompt),
		)
		if err != nil {
			return nil, fmt.Errorf("genkit URL analysis failed: %w", err)
		}
	}

	// –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
	if result.URLNote == nil {
		result.URLNote = &models.URLNote{
			Content:    "Analysis completed",
			Suspicious: false,
			Confidence: 0.5,
		}
	}

	result.URLNote.Timestamp = time.Now()

	return result, nil
}

// performHypothesisGeneration –≤—ã–ø–æ–ª–Ω—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≥–∏–ø–æ—Ç–µ–∑
func (analyzer *GenkitSecurityAnalyzer) performHypothesisGeneration(
	ctx context.Context, req *models.HypothesisRequest,
) (*models.HypothesisResponse, error) {
	var result *models.HypothesisResponse
	var err error

	// –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
	if analyzer.llmProvider != nil {
		result, err = analyzer.llmProvider.GenerateHypothesis(ctx, req)
		if err != nil {
			return nil, fmt.Errorf("failed to generate hypothesis: %w", err)
		}
	} else {
		// –ò—Å–ø–æ–ª—å–∑—É–µ–º Genkit –¥–ª—è Gemini
		prompt := llm.BuildHypothesisPrompt(req)
		result, _, err = genkit.GenerateData[models.HypothesisResponse](
			ctx, analyzer.genkitApp,
			ai.WithPrompt(prompt),
		)
		if err != nil {
			return nil, fmt.Errorf("genkit hypothesis generation failed: %w", err)
		}
	}

	// –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
	if result.Hypothesis == nil {
		result.Hypothesis = &models.SecurityHypothesis{
			ID:          uuid.New().String()[:8],
			Title:       "No hypothesis generated",
			Description: "Insufficient data",
			Confidence:  0.0,
			CreatedAt:   time.Now(),
			UpdatedAt:   time.Now(),
			Status:      models.HypothesisActive,
		}
	} else {
		// –ó–∞–ø–æ–ª–Ω—è–µ–º timestamp –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
		now := time.Now()
		if result.Hypothesis.CreatedAt.IsZero() {
			result.Hypothesis.CreatedAt = now
		}
		if result.Hypothesis.UpdatedAt.IsZero() {
			result.Hypothesis.UpdatedAt = now
		}
		// –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
		if result.Hypothesis.ID == "" {
			result.Hypothesis.ID = uuid.New().String()[:8]
		}
	}

	return result, nil
}

// –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫—ç—à–µ–º

// getCachedAnalysis –ø–æ–ª—É—á–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
func (analyzer *GenkitSecurityAnalyzer) getCachedAnalysis(cacheKey string) *CachedAnalysis {
	analyzer.cacheMutex.RLock()

	if cached, exists := analyzer.analysisCache[cacheKey]; exists {
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —É—Å—Ç–∞—Ä–µ–ª –ª–∏ –∫—ç—à
		if time.Since(cached.LastAnalyzed) < analyzer.cacheExpiry {
			analyzer.cacheMutex.RUnlock()
			return cached
		}
	}

	analyzer.cacheMutex.RUnlock()

	// –ï—Å–ª–∏ –∫—ç—à —É—Å—Ç–∞—Ä–µ–ª, —É–¥–∞–ª—è–µ–º –µ–≥–æ —Å –ø–æ–ª–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π
	analyzer.cacheMutex.Lock()
	defer analyzer.cacheMutex.Unlock()

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ (–¥—Ä—É–≥–∞—è –≥–æ—Ä—É—Ç–∏–Ω–∞ –º–æ–≥–ª–∞ —É–¥–∞–ª–∏—Ç—å)
	if cached, exists := analyzer.analysisCache[cacheKey]; exists {
		if time.Since(cached.LastAnalyzed) >= analyzer.cacheExpiry {
			delete(analyzer.analysisCache, cacheKey)
		}
	}

	return nil
}

// cacheAnalysis —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫—ç—à
func (analyzer *GenkitSecurityAnalyzer) cacheAnalysis(cacheKey string, resp *models.URLAnalysisResponse) {
	analyzer.cacheMutex.Lock()
	defer analyzer.cacheMutex.Unlock()

	analyzer.analysisCache[cacheKey] = &CachedAnalysis{
		URLPattern:     cacheKey,
		LastAnalyzed:   time.Now(),
		AnalysisResult: resp,
		AccessCount:    1,
		Confidence:     resp.URLNote.Confidence,
	}

	// –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –µ—Å–ª–∏ –∫—ç—à —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
	if len(analyzer.analysisCache) > 1000 {
		analyzer.cleanupCache()
	}
}

// updateCachedAnalysis –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
func (analyzer *GenkitSecurityAnalyzer) updateCachedAnalysis(cacheKey string, cached *CachedAnalysis) {
	analyzer.cacheMutex.Lock()
	defer analyzer.cacheMutex.Unlock()

	if existing, exists := analyzer.analysisCache[cacheKey]; exists {
		existing.AccessCount++
		existing.LastAnalyzed = time.Now()
	}
}

// cleanupCache –æ—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫—ç—à–∞
func (analyzer *GenkitSecurityAnalyzer) cleanupCache() {
	// –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
	if len(analyzer.analysisCache) < 500 {
		return
	}

	// –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ª–æ–≤–∏–Ω—É —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö
	type cacheItem struct {
		key    string
		cached *CachedAnalysis
	}

	items := make([]cacheItem, 0, len(analyzer.analysisCache))
	for key, cached := range analyzer.analysisCache {
		items = append(items, cacheItem{key, cached})
	}

	// –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –ø–µ—Ä–≤—ã–µ) - O(n log n) –≤–º–µ—Å—Ç–æ O(n¬≤)
	for i := 0; i < len(items)-1; i++ {
		for j := 0; j < len(items)-i-1; j++ {
			if items[j].cached.LastAnalyzed.Before(items[j+1].cached.LastAnalyzed) {
				items[j], items[j+1] = items[j+1], items[j]
			}
		}
	}

	// –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–≤–∏–Ω—É
	analyzer.analysisCache = make(map[string]*CachedAnalysis)
	for i := 0; i < len(items)/2; i++ {
		analyzer.analysisCache[items[i].key] = items[i].cached
	}
}

// –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å URL –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏

// updateURLPattern –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω URL —Å –Ω–æ–≤–æ–π –∑–∞–º–µ—Ç–∫–æ–π
func (analyzer *GenkitSecurityAnalyzer) updateURLPattern(
	siteContext *models.SiteContext, normalizedURL, method string, urlNote *models.URLNote,
) {
	patternKey := fmt.Sprintf("%s:%s", method, normalizedURL)

	var urlPattern *models.URLPattern
	if existing, exists := siteContext.URLPatterns[patternKey]; exists {
		urlPattern = existing
		urlPattern.LastSeen = time.Now()
		urlPattern.AccessCount++
		urlPattern.LastNote = urlNote
		urlPattern.Notes = append(urlPattern.Notes, *urlNote)
	} else {
		urlPattern = &models.URLPattern{
			Pattern:        normalizedURL,
			Method:         method,
			FirstSeen:      time.Now(),
			LastSeen:       time.Now(),
			LastNote:       urlNote,
			Notes:          []models.URLNote{*urlNote},
			Examples:       []string{normalizedURL},
			UserRoles:      []string{},               // –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
			RequestSamples: []models.RequestSample{}, // –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
		}
		siteContext.URLPatterns[patternKey] = urlPattern
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º purpose –µ—Å–ª–∏ –µ—Å—Ç—å –≤ –∑–∞–º–µ—Ç–∫–µ
	if urlNote.Content != "" {
		urlPattern.Purpose = urlNote.Content
	}

	siteContext.LastUpdated = time.Now()
}

// updateSiteContextWithURLNote –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–º–µ—Ç–∫–æ–π –ø–æ URL
func (analyzer *GenkitSecurityAnalyzer) updateSiteContextWithURLNote(
	siteContext *models.SiteContext, originalURL string, urlNote *models.URLNote,
) {
	// –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
	siteContext.DiscoveredEndpoints[originalURL] = true

	// –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
	siteContext.LastUpdated = time.Now()
}

// generateMainHypothesis –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–ª–∞–≤–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É –æ–± —É—è–∑–≤–∏–º–æ—Å—Ç–∏
func (analyzer *GenkitSecurityAnalyzer) generateMainHypothesis(siteContext *models.SiteContext) {
	// –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
	suspiciousPatterns := make([]*models.URLPattern, 0)
	attackSequences := make([][]*models.URLPattern, 0)

	for _, pattern := range siteContext.URLPatterns {
		if pattern.LastNote != nil && pattern.LastNote.Suspicious {
			suspiciousPatterns = append(suspiciousPatterns, pattern)
		}
	}

	// –ò—â–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—Ç–∞–∫ (–ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
	if len(suspiciousPatterns) >= 2 {
		attackSequences = append(attackSequences, suspiciousPatterns[:2])
	}

	// –ü–æ–ª—É—á–∞–µ–º —É—è–∑–≤–∏–º–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
	techVulns := make([]string, 0)
	if siteContext.TechStack != nil {
		// TODO: Implement tech vulnerability mapping
		if len(siteContext.TechStack.Frontend) > 0 {
			techVulns = append(techVulns, "XSS in frontend framework")
		}
	}

	// –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–∏–ø–æ—Ç–µ–∑—ã
	hypothesisReq := &models.HypothesisRequest{
		SiteContext:         siteContext,
		SuspiciousPatterns:  suspiciousPatterns,
		AttackSequences:     attackSequences,
		TechVulnerabilities: techVulns,
		PreviousHypothesis:  siteContext.MainHypothesis,
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≥–∏–ø–æ—Ç–µ–∑—ã
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	resp, err := analyzer.hypothesisFlow.Run(ctx, hypothesisReq)
	if err != nil {
		log.Printf("‚ùå Failed to generate hypothesis: %v", err)
		return
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
	siteContext.MainHypothesis = resp.Hypothesis
	siteContext.LastHypothesisUpdate = time.Now()
	siteContext.LastUpdated = time.Now()

	atomic.AddInt64(&analyzer.stats.hypothesisGenerated, 1)

	log.Printf("üéØ Generated new hypothesis: %s (confidence: %.2f)", resp.Hypothesis.Title, resp.Hypothesis.Confidence)

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ UI
	dto := map[string]interface{}{
		"type":       "hypothesis_update",
		"hypothesis": resp.Hypothesis,
		"reasoning":  resp.Reasoning,
		"host":       siteContext.Host,
	}
	analyzer.WsHub.Broadcast(dto)
}

// GetOptimizationStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
func (analyzer *GenkitSecurityAnalyzer) GetOptimizationStats() map[string]interface{} {
	total := atomic.LoadInt64(&analyzer.stats.totalRequests)
	filtered := atomic.LoadInt64(&analyzer.stats.filteredRequests)
	quick := atomic.LoadInt64(&analyzer.stats.quickAnalyses)
	full := atomic.LoadInt64(&analyzer.stats.fullAnalyses)
	cached := atomic.LoadInt64(&analyzer.stats.cacheHits)
	hypotheses := atomic.LoadInt64(&analyzer.stats.hypothesisGenerated)

	reductionRate := float64(0)
	if total > 0 {
		reductionRate = float64(filtered) / float64(total) * 100
	}

	cacheHitRate := float64(0)
	if quick > 0 {
		cacheHitRate = float64(cached) / float64(quick) * 100
	}

	stats := map[string]interface{}{
		"total_requests":         total,
		"filtered_requests":      filtered,
		"quick_analyses":         quick,
		"full_analyses":          full,
		"cache_hits":             cached,
		"hypotheses_generated":   hypotheses,
		"filter_reduction_rate":  reductionRate,
		"cache_hit_rate":         cacheHitRate,
		"efficiency_improvement": "Optimized analysis with filtering and caching",
	}

	return stats
}

// GetCurrentHypothesis –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –≥–∏–ø–æ—Ç–µ–∑—É –¥–ª—è —Ö–æ—Å—Ç–∞
func (analyzer *GenkitSecurityAnalyzer) GetCurrentHypothesis(host string) *models.SecurityHypothesis {
	analyzer.contextMutex.RLock()
	defer analyzer.contextMutex.RUnlock()

	if siteContext, exists := analyzer.siteContexts[host]; exists {
		return siteContext.MainHypothesis
	}

	return nil
}

// GenerateHypothesisForHost –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É –¥–ª—è —Ö–æ—Å—Ç–∞
func (analyzer *GenkitSecurityAnalyzer) GenerateHypothesisForHost(host string) (*models.HypothesisResponse, error) {
	analyzer.contextMutex.RLock()
	siteContext, exists := analyzer.siteContexts[host]
	analyzer.contextMutex.RUnlock()

	if !exists {
		return nil, fmt.Errorf("no context found for host: %s", host)
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
	if len(siteContext.URLPatterns) < 3 {
		return nil, fmt.Errorf("insufficient data: only %d URL patterns discovered", len(siteContext.URLPatterns))
	}

	// –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
	suspiciousPatterns := make([]*models.URLPattern, 0)
	attackSequences := make([][]*models.URLPattern, 0)

	for _, pattern := range siteContext.URLPatterns {
		if pattern.LastNote != nil && pattern.LastNote.Suspicious {
			suspiciousPatterns = append(suspiciousPatterns, pattern)
		}
	}

	// –ò—â–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—Ç–∞–∫
	if len(suspiciousPatterns) >= 2 {
		attackSequences = append(attackSequences, suspiciousPatterns[:2])
	}

	// –ü–æ–ª—É—á–∞–µ–º —É—è–∑–≤–∏–º–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
	techVulns := make([]string, 0)
	if siteContext.TechStack != nil {
		if len(siteContext.TechStack.Frontend) > 0 {
			techVulns = append(techVulns, "XSS in frontend framework")
		}
	}

	// –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–∏–ø–æ—Ç–µ–∑—ã
	hypothesisReq := &models.HypothesisRequest{
		SiteContext:         siteContext,
		SuspiciousPatterns:  suspiciousPatterns,
		AttackSequences:     attackSequences,
		TechVulnerabilities: techVulns,
		PreviousHypothesis:  siteContext.MainHypothesis,
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≥–∏–ø–æ—Ç–µ–∑—ã
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	resp, err := analyzer.hypothesisFlow.Run(ctx, hypothesisReq)
	if err != nil {
		return nil, fmt.Errorf("failed to generate hypothesis: %w", err)
	}

	// –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
	siteContext.MainHypothesis = resp.Hypothesis
	siteContext.LastHypothesisUpdate = time.Now()
	siteContext.LastUpdated = time.Now()

	atomic.AddInt64(&analyzer.stats.hypothesisGenerated, 1)

	log.Printf("üéØ Manual hypothesis generated for %s: %s (confidence: %.2f)",
		host, resp.Hypothesis.Title, resp.Hypothesis.Confidence)

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ UI
	dto := map[string]interface{}{
		"type":       "hypothesis_update",
		"hypothesis": resp.Hypothesis,
		"reasoning":  resp.Reasoning,
		"host":       host,
		"manual":     true, // —Ñ–ª–∞–≥ —á—Ç–æ —ç—Ç–æ —Ä—É—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
	}
	analyzer.WsHub.Broadcast(dto)

	return resp, nil
}

// GetAllHypotheses –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –≥–∏–ø–æ—Ç–µ–∑—ã –¥–ª—è –≤—Å–µ—Ö —Ö–æ—Å—Ç–æ–≤
func (analyzer *GenkitSecurityAnalyzer) GetAllHypotheses() map[string]*models.SecurityHypothesis {
	analyzer.contextMutex.RLock()
	defer analyzer.contextMutex.RUnlock()

	result := make(map[string]*models.SecurityHypothesis)
	for host, context := range analyzer.siteContexts {
		if context.MainHypothesis != nil {
			result[host] = context.MainHypothesis
		}
	}

	return result
}

// GetSiteContext –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ö–æ—Å—Ç–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
func (analyzer *GenkitSecurityAnalyzer) GetSiteContext(host string) *models.SiteContext {
	analyzer.contextMutex.RLock()
	defer analyzer.contextMutex.RUnlock()

	return analyzer.siteContexts[host]
}
